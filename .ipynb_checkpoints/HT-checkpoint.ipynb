{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "NddLtDKSihGp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16545,
     "status": "ok",
     "timestamp": 1637127640556,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "NddLtDKSihGp",
    "outputId": "1807fe06-cb92-44b2-e6eb-3a76ca50c414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "-cv9Rz_TiaB6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1637127640557,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "-cv9Rz_TiaB6",
    "outputId": "8adfa09f-bbe0-40fb-bd6b-94f5f38446cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/HT1018\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My Drive/HT1018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "MFUq3xbCXGWV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1637127640557,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "MFUq3xbCXGWV",
    "outputId": "2150f883-dfe0-41d8-baf9-1013257aa814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 17 05:40:39 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   33C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "HWYHe-5FXHwl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1637127640557,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "HWYHe-5FXHwl",
    "outputId": "99ceae26-93df-44aa-d90a-dd56c83281c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 13.6 gigabytes of available RAM\n",
      "\n",
      "Not using a high-RAM runtime\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf6c0d69",
   "metadata": {
    "executionInfo": {
     "elapsed": 14122,
     "status": "ok",
     "timestamp": 1637127654676,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "bf6c0d69"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from usr_encoder import USREncoder\n",
    "from logit import Out\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "\n",
    "\n",
    "def set_random_seed(seed = 10,deterministic=False,benchmark=False):\n",
    "    random.seed(seed)\n",
    "    np.random.random(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    if benchmark:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    return    \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_flag = False  #测试标志，True时加载保存好的模型进行测试 \n",
    "filename = './N20K2M32L8_Layer2_em128'\n",
    "path_checkpoint = filename+'/ckpt_best_0.pth'  # 断点路径\n",
    "\n",
    "\n",
    "EMx = 128\n",
    "EMy = 128\n",
    "EM = 128\n",
    "N = 20\n",
    "K = 2\n",
    "L = 8\n",
    "J = 0\n",
    "M = 32\n",
    "D = 500\n",
    "FF = 512\n",
    "txPower = 23 # dBm\n",
    "noisePower = -99 # dBm\n",
    "set_random_seed(10)\n",
    "\n",
    "location = 'control'\n",
    "channel = 'iid'\n",
    "use_cov = True\n",
    "sigma2s = np.ones([N,1])  \n",
    "txPowerN = 0\n",
    "noisePowerN = noisePower + 15.3 + 37.6*np.log10(D*math.tan(math.pi/6)) - txPower\n",
    "matrx_Type = 'Gaussian'\n",
    "VSIZE = 512\n",
    "BSIZE = 256\n",
    "TSIZE = 5000\n",
    "if location =='uniform':\n",
    "    NodeSIZE = 2*L+1\n",
    "else:\n",
    "    NodeSIZE = 2*L    \n",
    "BNUM = 5000\n",
    "EP = 120\n",
    "\n",
    "#ma = torch.eye(N).to(device)\n",
    "#mb = torch.ones(N).unsqueeze(0).to(device)\n",
    "#ma = torch.cat((ma,mb),0)\n",
    "#mc = torch.ones(N+1).unsqueeze(1).to(device)\n",
    "#mask = ~torch.cat((ma,mc),1).bool()\n",
    "mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0ebe09c",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1637127654676,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "c0ebe09c"
   },
   "outputs": [],
   "source": [
    "def sensingMatrixDesign(N,J,L,type):\n",
    "    Ne = N*2**J\n",
    "    if type=='Gaussian':\n",
    "        A = (np.random.normal(loc=0, scale=1, size=(L, Ne))+1j*np.random.normal(loc=0, scale=1, size=(L, Ne)))*np.sqrt(0.5)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad2e2461",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1637127654676,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "ad2e2461"
   },
   "outputs": [],
   "source": [
    "def channelGeneration(N,M,sigma2s,channel):   \n",
    "\n",
    "    if channel == 'noniid':\n",
    "        Lp=2\n",
    "        theta = np.random.uniform(low=-math.pi/6, high=math.pi/6, size=(N,Lp))\n",
    "        alfa = np.sqrt(1/2)*(np.random.normal(loc=0, scale=1, size=(N, Lp)) + 1j*np.random.normal(loc=0, scale=1, size=(N, Lp)))\n",
    "        a1=range(M)\n",
    "        a2=1j*math.pi*np.sin(theta)\n",
    "        a3=np.kron(a1,a2).reshape((N,Lp,M))\n",
    "        a = np.exp(a3)\n",
    "        hh=np.expand_dims(alfa,2).repeat(M,axis=2)*a\n",
    "        H = hh.sum(axis=1)/np.sqrt(Lp)\n",
    "    else:\n",
    "        H = np.sqrt(1/2)*(np.random.normal(loc=0, scale=1, size=(N, M)) + 1j*np.random.normal(loc=0, scale=1, size=(N, M))) \n",
    "\n",
    "    H = np.sqrt(np.tile(sigma2s,(1,M)))*H # sigma2s large-scale fading component\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bd8f03a",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1637127654677,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "4bd8f03a"
   },
   "outputs": [],
   "source": [
    "def signalGeneration(N,K,L,J,M,H,txPowerMax,noisePower):\n",
    "    user_idx = np.random.permutation(N)\n",
    "    user_idx[0:K] = np.sort(user_idx[0:K])\n",
    "    user_supp = np.zeros([N])\n",
    "    user_supp[user_idx[0:K]] = 1\n",
    "\n",
    "    # Data of active users  \n",
    "    data_idx = np.random.randint(2**J,size=K) # the data indices for active users\n",
    "\n",
    "    # Combined support\n",
    "    supp = np.zeros([2**J*N])\n",
    "    supp[user_idx[0:K]*2**J + data_idx] = 1\n",
    "\n",
    "    # Signal generation \n",
    "    Ne = N*2**J\n",
    "    Heff = np.repeat(H, 2**J, axis=0) # eff. channel; channel for sequences of one users are equal.\n",
    "    x = np.zeros([Ne,M])+1j*np.zeros([Ne,M])\n",
    "    x[(supp==1),:] = Heff[(supp==1),:] \n",
    "\n",
    "    # Noise setup with power control\n",
    "    sigma2n = (10**((noisePower)/10)) \n",
    "    txPower = 10**(txPowerMax/10)\n",
    "    sigma2n = sigma2n/txPower\n",
    "    return x,user_supp,supp,user_idx,data_idx,sigma2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17c74af7",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1637127654677,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "17c74af7"
   },
   "outputs": [],
   "source": [
    "def datasetGeneration(datasize,N,J,L,matrx_Type,M,K,txPowerN,noisePowerN,location,channel,use_cov):   \n",
    "    if location=='uniform':\n",
    "        A_data = np.zeros([datasize, N, 2*L+1])\n",
    "    else: \n",
    "        A_data = np.zeros([datasize, N, 2*L])\n",
    "    if use_cov == True:\n",
    "        Cov_data = np.zeros([datasize, 2*L*L])\n",
    "    else:\n",
    "        Cov_data = np.zeros([datasize, 2*L*M])\n",
    "    supp_data = np.zeros([datasize, N])\n",
    "        \n",
    "    for mc in range(datasize):\n",
    "\n",
    "        # Sequence generation\n",
    "        A = sensingMatrixDesign(N,J,L,matrx_Type)\n",
    "    \n",
    "\n",
    "        # if location=='uniform':\n",
    "        #     distance = np.zeros([N,1])  \n",
    "        #     x_Range = D*math.tan(math.pi/6)*3/2\n",
    "        #     y_Range = D\n",
    "          \n",
    "        #     for iUE in range(N):\n",
    "        #         RD = 0\n",
    "        #         while RD<=50:\n",
    "        #             x_Posi = np.random.uniform(x_Range*(-2/3), x_Range*(1/3))\n",
    "        #             y_Posi = np.random.uniform(y_Range*(-1/2), y_Range*(1/2))\n",
    "\n",
    "        #             if y_Posi > x_Posi*math.tan(math.pi/3)+D:\n",
    "        #                 x_Posi = x_Posi+x_Range\n",
    "        #                 y_Posi = y_Posi-y_Range/2\n",
    "        #             elif y_Posi < -x_Posi*math.tan(math.pi/3)-D:\n",
    "        #                 x_Posi = x_Posi+x_Range\n",
    "        #                 y_Posi = y_Posi+y_Range/2\n",
    "\n",
    "        #             RD = np.sqrt(x_Posi**2 + y_Posi**2)\n",
    "        #         distance[iUE,0]=RD\n",
    "\n",
    "        #     sigma2dB = 128-15.3-37.6*np.log10(distance)\n",
    "        #     sigma2s = 10**(sigma2dB/10)   \n",
    "            \n",
    "\n",
    "        # Gaussian channel\n",
    "        H = channelGeneration(N,M,sigma2s,channel)\n",
    "        \n",
    "\n",
    "        # Sparse signal\n",
    "        x,user_supp,supp,user_idx,data_idx,sigma2n = signalGeneration(N,K,L,J,M,H,txPowerN,noisePowerN)\n",
    "\n",
    "        # Additive noise\n",
    "        w = np.sqrt(1/2)*(np.random.normal(loc=0, scale=1, size=(L,M))+1j*np.random.normal(loc=0, scale=1, size=(L,M)))*np.sqrt(sigma2n)\n",
    "\n",
    "        # System model\n",
    "        y = np.dot(A,x)+ w\n",
    "        if use_cov == True:        \n",
    "            Cov = 1/M*np.dot(y,y.T.conj()).reshape(-1)\n",
    "        else:\n",
    "            Cov = y.reshape(-1)    \n",
    "\n",
    "        \n",
    "        Cov_data[mc,:] = np.hstack((np.real(Cov), np.imag(Cov)))\n",
    "        supp_data[mc,:] = supp\n",
    "\n",
    "        if location=='uniform':\n",
    "            A_data[mc,:,:-1] = np.vstack((np.real(A), np.imag(A))).T\n",
    "            A_data[mc,:,-1] = np.squeeze(distance)\n",
    "        else:\n",
    "            A_data[mc,:,:] = np.vstack((np.real(A), np.imag(A))).T  \n",
    "\n",
    "    dA = torch.FloatTensor(A_data).to(device)\n",
    "    dCov = torch.FloatTensor(Cov_data).to(device)\n",
    "    dsupp = torch.FloatTensor(supp_data).to(device)\n",
    "    \n",
    "    return dA, dCov, dsupp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05f022b2",
   "metadata": {
    "executionInfo": {
     "elapsed": 10624,
     "status": "ok",
     "timestamp": 1637127665297,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "05f022b2"
   },
   "outputs": [],
   "source": [
    "vA, vCov, vsupp = datasetGeneration(VSIZE,N,J,L,matrx_Type,M,K,txPowerN,noisePowerN,location,channel,use_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47045bca",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1637127665298,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "47045bca"
   },
   "outputs": [],
   "source": [
    "class SAD(nn.Module):\n",
    "    def __init__(self,L,EMx,EMy,EM,FF,NodeSIZE):\n",
    "        super(SAD,self).__init__()\n",
    "        \n",
    "        if use_cov == True:\n",
    "            # self.cov = torch.nn.Sequential(\n",
    "            #      nn.Linear(2*L*L, FF),\n",
    "            #      nn.ReLU(),\n",
    "            #      nn.Linear(FF, EMy)\n",
    "            #    )\n",
    "            self.cov = nn.Linear(2*L*L, EMy)\n",
    "        else:\n",
    "            self.cov = nn.Linear(2*L*M, EMy)\n",
    "\n",
    "                \n",
    "        self.usr1 = USREncoder(\n",
    "            n_heads=8,\n",
    "            embed_dim=EM,\n",
    "            y_dim=EMy,\n",
    "            x_dim=EMx, \n",
    "            feed_forward_hidden = FF,\n",
    "            node_dim = NodeSIZE,\n",
    "            normalization='batch'\n",
    "                       )    \n",
    "        \n",
    "        self.usr2 = USREncoder(\n",
    "            n_heads=8,\n",
    "            embed_dim=EM,\n",
    "            y_dim=EMy,\n",
    "            x_dim=EMx,\n",
    "            feed_forward_hidden = FF,\n",
    "            normalization='batch'\n",
    "                       )\n",
    "        \n",
    "        # self.usr3 = USREncoder(\n",
    "        #     n_heads=8,\n",
    "        #     embed_dim=EM,\n",
    "        #     y_dim=EMy,\n",
    "        #     x_dim=EMx, \n",
    "        #     feed_forward_hidden = FF,\n",
    "        #     normalization='batch'\n",
    "        #                )\n",
    "     \n",
    "        # self.usr4 = USREncoder(\n",
    "        #      n_heads=8,\n",
    "        #      embed_dim=EM,\n",
    "        #      y_dim=EMy,\n",
    "        #      x_dim=EMx, \n",
    "        #      feed_forward_hidden = FF,\n",
    "        #      normalization='batch'\n",
    "        #                 )\n",
    "             \n",
    "        # self.usr5 = USREncoder(\n",
    "        #      n_heads=8,\n",
    "        #      embed_dim=EM,\n",
    "        #      y_dim=EMy,\n",
    "        #      x_dim=EMx, \n",
    "        #      feed_forward_hidden = FF,\n",
    "        #      normalization='batch'\n",
    "        #                 )\n",
    "      \n",
    "        # self.usr6 = USREncoder(\n",
    "        #      n_heads=8,\n",
    "        #      embed_dim=EM,\n",
    "        #      y_dim=EMy,\n",
    "        #      feed_forward_hidden = FF,\n",
    "        #      normalization='batch'\n",
    "        #                 )\n",
    "        \n",
    "       # self.usr7 = USREncoder(\n",
    "       #     n_heads=8,\n",
    "       #     embed_dim=EM,\n",
    "       #     y_dim=EMy,\n",
    "       #     feed_forward_hidden = FF,\n",
    "       #     normalization='batch'\n",
    "      #                 )\n",
    "        \n",
    "       # self.usr8 = USREncoder(\n",
    "       #     n_heads=8,\n",
    "       #     embed_dim=EM,\n",
    "       #     y_dim=EMy,\n",
    "       #     feed_forward_hidden = FF,\n",
    "       #     normalization='batch'\n",
    "       #                )    \n",
    "        \n",
    "        self.out = Out(\n",
    "            n_heads=8,\n",
    "            embed_dim=EM,\n",
    "            y_dim=EMy,\n",
    "            x_dim=EMx\n",
    "                 )\n",
    "         \n",
    "    def forward(self,x,y,mask):\n",
    "        y = self.cov(y).unsqueeze(1)\n",
    "        x, y = self.usr1(x,y,mask)      \n",
    "        x, y = self.usr2(x,y,mask)      \n",
    "        # x, y = self.usr3(x,y,mask)      \n",
    "        # x, y = self.usr4(x,y,mask)      \n",
    "        # x, y = self.usr5(x,y,mask)      \n",
    "        # x, y = self.usr6(x,y,mask) \n",
    "      #  x, y = self.usr7(x,y,mask)  \n",
    "      #  x, y = self.usr8(x,y,mask)       \n",
    "        output = self.out(x,y)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7VpkvYueS5Y5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1637127665298,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "7VpkvYueS5Y5",
    "outputId": "f3ac92a5-9a72-4430-cf8a-720624f99ebb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From epoch 0\n"
     ]
    }
   ],
   "source": [
    "model = SAD(L,EMx,EMy,EM,FF,NodeSIZE).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([(N-K)/K]).to(device))\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "lr_schedule = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[90,97],gamma=0.1)\n",
    "\n",
    "if test_flag:\n",
    "    checkpoint = torch.load(path_checkpoint, map_location=torch.device(device))  # 加载断点\n",
    "    model.load_state_dict(checkpoint['net'])  # 加载模型可学习参数\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])  # 加载优化器参数\n",
    "    start_epoch = checkpoint['epoch']  # 设置开始的epoch\n",
    "    lr_schedule.load_state_dict(checkpoint['lr_schedule'])\n",
    "  #  lr_schedule = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[90,97],gamma=0.1,last_epoch=0)\n",
    "\n",
    "    print('Load epoch {} successfully'.format(start_epoch))\n",
    "else:\n",
    "    start_epoch = -1\n",
    "    print('From epoch 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fb93f4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53013934,
     "status": "ok",
     "timestamp": 1637180679224,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "1fb93f4f",
    "outputId": "4d21fe13-5db3-4246-862e-7dc4fdafc292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\t Loss: 0.114483\n",
      "Test set: Loss: 0.0504, Error rate: 595/10240 (5.81%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 1\t Loss: 0.035990\n",
      "Test set: Loss: 0.0251, Error rate: 268/10240 (2.62%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 2\t Loss: 0.020265\n",
      "Test set: Loss: 0.0165, Error rate: 197/10240 (1.92%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 3\t Loss: 0.013453\n",
      "Test set: Loss: 0.0121, Error rate: 137/10240 (1.34%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 4\t Loss: 0.009761\n",
      "Test set: Loss: 0.0091, Error rate: 104/10240 (1.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 5\t Loss: 0.007431\n",
      "Test set: Loss: 0.0069, Error rate: 90/10240 (0.88%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 6\t Loss: 0.005787\n",
      "Test set: Loss: 0.0046, Error rate: 72/10240 (0.70%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 7\t Loss: 0.004682\n",
      "Test set: Loss: 0.0042, Error rate: 62/10240 (0.61%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 8\t Loss: 0.003841\n",
      "Test set: Loss: 0.0030, Error rate: 46/10240 (0.45%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 9\t Loss: 0.003207\n",
      "Test set: Loss: 0.0027, Error rate: 32/10240 (0.31%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 10\t Loss: 0.002720\n",
      "Test set: Loss: 0.0021, Error rate: 30/10240 (0.29%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 11\t Loss: 0.002358\n",
      "Test set: Loss: 0.0021, Error rate: 31/10240 (0.30%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 12\t Loss: 0.002119\n",
      "Test set: Loss: 0.0019, Error rate: 26/10240 (0.25%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 13\t Loss: 0.001892\n",
      "Test set: Loss: 0.0024, Error rate: 28/10240 (0.27%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 14\t Loss: 0.001682\n",
      "Test set: Loss: 0.0015, Error rate: 21/10240 (0.21%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 15\t Loss: 0.001550\n",
      "Test set: Loss: 0.0011, Error rate: 20/10240 (0.20%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 16\t Loss: 0.001430\n",
      "Test set: Loss: 0.0010, Error rate: 15/10240 (0.15%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 17\t Loss: 0.001293\n",
      "Test set: Loss: 0.0010, Error rate: 15/10240 (0.15%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 18\t Loss: 0.001202\n",
      "Test set: Loss: 0.0010, Error rate: 13/10240 (0.13%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 19\t Loss: 0.001115\n",
      "Test set: Loss: 0.0007, Error rate: 11/10240 (0.11%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 20\t Loss: 0.001047\n",
      "Test set: Loss: 0.0006, Error rate: 8/10240 (0.08%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 21\t Loss: 0.000963\n",
      "Test set: Loss: 0.0009, Error rate: 11/10240 (0.11%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 22\t Loss: 0.000892\n",
      "Test set: Loss: 0.0005, Error rate: 6/10240 (0.06%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 23\t Loss: 0.000820\n",
      "Test set: Loss: 0.0004, Error rate: 5/10240 (0.05%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 24\t Loss: 0.000779\n",
      "Test set: Loss: 0.0004, Error rate: 8/10240 (0.08%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 25\t Loss: 0.000716\n",
      "Test set: Loss: 0.0004, Error rate: 4/10240 (0.04%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 26\t Loss: 0.000689\n",
      "Test set: Loss: 0.0009, Error rate: 12/10240 (0.12%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 27\t Loss: 0.000650\n",
      "Test set: Loss: 0.0002, Error rate: 4/10240 (0.04%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 28\t Loss: 0.000606\n",
      "Test set: Loss: 0.0003, Error rate: 4/10240 (0.04%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 29\t Loss: 0.000583\n",
      "Test set: Loss: 0.0002, Error rate: 4/10240 (0.04%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 30\t Loss: 0.000547\n",
      "Test set: Loss: 0.0004, Error rate: 7/10240 (0.07%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 31\t Loss: 0.000524\n",
      "Test set: Loss: 0.0004, Error rate: 6/10240 (0.06%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 32\t Loss: 0.000507\n",
      "Test set: Loss: 0.0003, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 33\t Loss: 0.000486\n",
      "Test set: Loss: 0.0004, Error rate: 4/10240 (0.04%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 34\t Loss: 0.000473\n",
      "Test set: Loss: 0.0002, Error rate: 3/10240 (0.03%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 35\t Loss: 0.000455\n",
      "Test set: Loss: 0.0003, Error rate: 3/10240 (0.03%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 36\t Loss: 0.000442\n",
      "Test set: Loss: 0.0002, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 37\t Loss: 0.000430\n",
      "Test set: Loss: 0.0001, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 38\t Loss: 0.000418\n",
      "Test set: Loss: 0.0002, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 39\t Loss: 0.000388\n",
      "Test set: Loss: 0.0004, Error rate: 7/10240 (0.07%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 40\t Loss: 0.000388\n",
      "Test set: Loss: 0.0002, Error rate: 6/10240 (0.06%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 41\t Loss: 0.000384\n",
      "Test set: Loss: 0.0001, Error rate: 1/10240 (0.01%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 42\t Loss: 0.000368\n",
      "Test set: Loss: 0.0001, Error rate: 1/10240 (0.01%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 43\t Loss: 0.000372\n",
      "Test set: Loss: 0.0002, Error rate: 3/10240 (0.03%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 44\t Loss: 0.000357\n",
      "Test set: Loss: 0.0001, Error rate: 1/10240 (0.01%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 45\t Loss: 0.000339\n",
      "Test set: Loss: 0.0001, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 46\t Loss: 0.000341\n",
      "Test set: Loss: 0.0001, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 47\t Loss: 0.000338\n",
      "Test set: Loss: 0.0001, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 48\t Loss: 0.000332\n",
      "Test set: Loss: 0.0002, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 49\t Loss: 0.000318\n",
      "Test set: Loss: 0.0001, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 50\t Loss: 0.000318\n",
      "Test set: Loss: 0.0001, Error rate: 1/10240 (0.01%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 51\t Loss: 0.000298\n",
      "Test set: Loss: 0.0001, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 52\t Loss: 0.000302\n",
      "Test set: Loss: 0.0001, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 53\t Loss: 0.000287\n",
      "Test set: Loss: 0.0002, Error rate: 1/10240 (0.01%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 54\t Loss: 0.000301\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 55\t Loss: 0.000284\n",
      "Test set: Loss: 0.0002, Error rate: 5/10240 (0.05%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 56\t Loss: 0.000282\n",
      "Test set: Loss: 0.0002, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 57\t Loss: 0.000274\n",
      "Test set: Loss: 0.0002, Error rate: 3/10240 (0.03%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 58\t Loss: 0.000283\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 59\t Loss: 0.000275\n",
      "Test set: Loss: 0.0002, Error rate: 1/10240 (0.01%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 60\t Loss: 0.000262\n",
      "Test set: Loss: 0.0001, Error rate: 1/10240 (0.01%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 61\t Loss: 0.000263\n",
      "Test set: Loss: 0.0001, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 62\t Loss: 0.000253\n",
      "Test set: Loss: 0.0001, Error rate: 1/10240 (0.01%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 63\t Loss: 0.000248\n",
      "Test set: Loss: 0.0001, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 64\t Loss: 0.000253\n",
      "Test set: Loss: 0.0001, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 65\t Loss: 0.000248\n",
      "Test set: Loss: 0.0001, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 66\t Loss: 0.000244\n",
      "Test set: Loss: 0.0001, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 67\t Loss: 0.000244\n",
      "Test set: Loss: 0.0001, Error rate: 1/10240 (0.01%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 68\t Loss: 0.000233\n",
      "Test set: Loss: 0.0001, Error rate: 1/10240 (0.01%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 69\t Loss: 0.000241\n",
      "Test set: Loss: 0.0001, Error rate: 3/10240 (0.03%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 70\t Loss: 0.000232\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 71\t Loss: 0.000237\n",
      "Test set: Loss: 0.0001, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 72\t Loss: 0.000223\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 73\t Loss: 0.000229\n",
      "Test set: Loss: 0.0001, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 74\t Loss: 0.000217\n",
      "Test set: Loss: 0.0011, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 75\t Loss: 0.000221\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 76\t Loss: 0.000221\n",
      "Test set: Loss: 0.0001, Error rate: 1/10240 (0.01%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 77\t Loss: 0.000220\n",
      "Test set: Loss: 0.0002, Error rate: 3/10240 (0.03%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 78\t Loss: 0.000221\n",
      "Test set: Loss: 0.0001, Error rate: 1/10240 (0.01%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 79\t Loss: 0.000216\n",
      "Test set: Loss: 0.0001, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 80\t Loss: 0.000205\n",
      "Test set: Loss: 0.0000, Error rate: 1/10240 (0.01%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 81\t Loss: 0.000201\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 82\t Loss: 0.000213\n",
      "Test set: Loss: 0.0002, Error rate: 3/10240 (0.03%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 83\t Loss: 0.000204\n",
      "Test set: Loss: 0.0001, Error rate: 1/10240 (0.01%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 84\t Loss: 0.000203\n",
      "Test set: Loss: 0.0002, Error rate: 4/10240 (0.04%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 85\t Loss: 0.000201\n",
      "Test set: Loss: 0.0002, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 86\t Loss: 0.000193\n",
      "Test set: Loss: 0.0011, Error rate: 4/10240 (0.04%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 87\t Loss: 0.000194\n",
      "Test set: Loss: 0.0001, Error rate: 2/10240 (0.02%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 88\t Loss: 0.000203\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 89\t Loss: 0.000195\n",
      "Test set: Loss: 0.0001, Error rate: 1/10240 (0.01%)\n",
      "learning rate: 0.0001\n",
      "\n",
      "\n",
      "Train Epoch: 90\t Loss: 0.000116\n",
      "Test set: Loss: 0.0001, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1e-05\n",
      "\n",
      "\n",
      "Train Epoch: 91\t Loss: 0.000072\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1e-05\n",
      "\n",
      "\n",
      "Train Epoch: 92\t Loss: 0.000068\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1e-05\n",
      "\n",
      "\n",
      "Train Epoch: 93\t Loss: 0.000055\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1e-05\n",
      "\n",
      "\n",
      "Train Epoch: 94\t Loss: 0.000050\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1e-05\n",
      "\n",
      "\n",
      "Train Epoch: 95\t Loss: 0.000048\n",
      "Test set: Loss: 0.0001, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1e-05\n",
      "\n",
      "\n",
      "Train Epoch: 96\t Loss: 0.000050\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1e-05\n",
      "\n",
      "\n",
      "Train Epoch: 97\t Loss: 0.000046\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 98\t Loss: 0.000044\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 99\t Loss: 0.000046\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 100\t Loss: 0.000045\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 101\t Loss: 0.000043\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 102\t Loss: 0.000040\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 103\t Loss: 0.000044\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 104\t Loss: 0.000043\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 105\t Loss: 0.000043\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 106\t Loss: 0.000043\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 107\t Loss: 0.000040\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 108\t Loss: 0.000043\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 109\t Loss: 0.000041\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 110\t Loss: 0.000041\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 111\t Loss: 0.000041\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 112\t Loss: 0.000040\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 113\t Loss: 0.000038\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 114\t Loss: 0.000039\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 115\t Loss: 0.000040\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 116\t Loss: 0.000035\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 117\t Loss: 0.000040\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 118\t Loss: 0.000037\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n",
      "Train Epoch: 119\t Loss: 0.000038\n",
      "Test set: Loss: 0.0000, Error rate: 0/10240 (0.00%)\n",
      "learning rate: 1.0000000000000002e-06\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch+1, EP):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i in range(BNUM):  \n",
    "        bA, bCov, bsupp = datasetGeneration(BSIZE,N,J,L,matrx_Type,M,K,txPowerN,noisePowerN,location,channel,use_cov)\n",
    "        optimizer.zero_grad()   \n",
    "        logit = model(bA,bCov,mask)\n",
    "        loss = criterion(logit, bsupp)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        train_loss += (2*K/N)*loss.item()\n",
    "    loss_mean = train_loss / BNUM\n",
    "    print('Train Epoch: {}\\t Loss: {:.6f}'.format(epoch, loss_mean))    \n",
    "        \n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        #vA, vCov, vsupp = bA, bCov, bsupp \n",
    "        vlogit = model(vA,vCov,mask)\n",
    "        vloss = criterion(vlogit, vsupp).item()\n",
    "        vprob = torch.sigmoid(vlogit)\n",
    "        vpred = torch.zeros(vprob.size()).to(device)\n",
    "        vpred[vprob>=0.5]=1\n",
    "        err = N*VSIZE-(vpred==vsupp).sum().sum().item()\n",
    "\n",
    "    print('Test set: Loss: {:.4f}, Error rate: {}/{} ({:.2f}%)'.format((2*K/N)*vloss, err, N*VSIZE, 100. * err/N/VSIZE)) \n",
    "    print('learning rate:',optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "    print('\\n')  \n",
    "\n",
    "    lr_schedule.step()\n",
    "\n",
    "    checkpoint = {\n",
    "        'net': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'lr_schedule': lr_schedule.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir(filename):\n",
    "        os.mkdir(filename)\n",
    "    torch.save(checkpoint, filename+'/ckpt_best_%s.pth' % (str(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b206d5ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1589,
     "status": "ok",
     "timestamp": 1637180680810,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "b206d5ac",
    "outputId": "31bdcf82-bc2e-44a8-cd8f-b98b8fc49e14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time= 0.0067596435546875\n"
     ]
    }
   ],
   "source": [
    "tA, tCov, tsupp = datasetGeneration(TSIZE,N,J,L,matrx_Type,M,K,txPowerN,noisePowerN,location,channel,use_cov)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    tlogit = model(tA,tCov,mask)\n",
    "    tprob = torch.sigmoid(tlogit)\n",
    "end = time.time()\n",
    "print('time=', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "yqKZG1nvlfR6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1637180681292,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "yqKZG1nvlfR6",
    "outputId": "315d1cc3-e073-4a2e-bf1d-3d99c49696fe"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM = 200\n",
    "min_g = tprob[tprob>0].min().item()\n",
    "max_g = tprob.max().item()\n",
    "set_1 = np.exp(np.linspace(np.log(min_g*0.95),np.log(max_g*1.05),int(NUM/2)))\n",
    "set_2 = np.linspace(min_g*0.95,max_g*1.05,int(NUM/2))\n",
    "TH = np.sort(np.concatenate((set_1,set_2)))\n",
    "pm_cov = np.zeros([NUM,1])\n",
    "pf_cov = np.zeros([NUM,1])\n",
    "\n",
    "for idx in range(NUM):\n",
    "    th = TH[idx]\n",
    "    th_supp = np.zeros(tsupp.size())\n",
    "    th_supp[(tprob>=th).cpu()]=1\n",
    "    detect = th_supp*(tsupp.cpu().numpy())\n",
    "    pm_cov[idx] = 1-detect.sum()/K/TSIZE\n",
    "    falarm = th_supp-detect\n",
    "    pf_cov[idx] = falarm.sum()/(N-K)/TSIZE \n",
    "\n",
    "plt.plot(pm_cov, pf_cov)  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4NJOJGz7mgAa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1637180681293,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "4NJOJGz7mgAa",
    "outputId": "dc40a3b5-cb79-4fb5-a5f4-c1e281063b14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [9.999999999998899e-05],\n",
       " [0.00019999999999997797],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm_cov.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "EcRTgXbheWC1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1637180681601,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "EcRTgXbheWC1",
    "outputId": "46483508-912a-4874-bddb-60d5aa546a82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0],\n",
       " [1.0],\n",
       " [0.011322222222222223],\n",
       " [0.005733333333333333],\n",
       " [0.003933333333333334],\n",
       " [0.003],\n",
       " [0.0021444444444444445],\n",
       " [0.0018333333333333333],\n",
       " [0.0016],\n",
       " [0.001377777777777778],\n",
       " [0.0011777777777777778],\n",
       " [0.0011],\n",
       " [0.0009555555555555555],\n",
       " [0.0008444444444444444],\n",
       " [0.0008222222222222221],\n",
       " [0.0007888888888888889],\n",
       " [0.000711111111111111],\n",
       " [0.000688888888888889],\n",
       " [0.0006222222222222223],\n",
       " [0.0006],\n",
       " [0.0005777777777777778],\n",
       " [0.0005444444444444445],\n",
       " [0.0005444444444444445],\n",
       " [0.000488888888888889],\n",
       " [0.0004666666666666667],\n",
       " [0.0004333333333333333],\n",
       " [0.00041111111111111106],\n",
       " [0.00038888888888888887],\n",
       " [0.00038888888888888887],\n",
       " [0.00036666666666666667],\n",
       " [0.0003555555555555555],\n",
       " [0.0003222222222222222],\n",
       " [0.0002888888888888889],\n",
       " [0.0002777777777777778],\n",
       " [0.00025555555555555553],\n",
       " [0.0002444444444444445],\n",
       " [0.00022222222222222223],\n",
       " [0.00022222222222222223],\n",
       " [0.00022222222222222223],\n",
       " [0.00022222222222222223],\n",
       " [0.0002111111111111111],\n",
       " [0.0002],\n",
       " [0.00018888888888888888],\n",
       " [0.00018888888888888888],\n",
       " [0.00018888888888888888],\n",
       " [0.00018888888888888888],\n",
       " [0.00018888888888888888],\n",
       " [0.00017777777777777776],\n",
       " [0.00017777777777777776],\n",
       " [0.00017777777777777776],\n",
       " [0.00017777777777777776],\n",
       " [0.00017777777777777776],\n",
       " [0.00017777777777777776],\n",
       " [0.00015555555555555556],\n",
       " [0.00015555555555555556],\n",
       " [0.00015555555555555556],\n",
       " [0.00015555555555555556],\n",
       " [0.00014444444444444444],\n",
       " [0.0001333333333333333],\n",
       " [0.0001333333333333333],\n",
       " [0.0001333333333333333],\n",
       " [0.00011111111111111112],\n",
       " [0.00011111111111111112],\n",
       " [0.00011111111111111112],\n",
       " [0.00011111111111111112],\n",
       " [0.0001],\n",
       " [7.777777777777778e-05],\n",
       " [7.777777777777778e-05],\n",
       " [6.666666666666666e-05],\n",
       " [5.555555555555556e-05],\n",
       " [5.555555555555556e-05],\n",
       " [5.555555555555556e-05],\n",
       " [4.444444444444444e-05],\n",
       " [4.444444444444444e-05],\n",
       " [4.444444444444444e-05],\n",
       " [4.444444444444444e-05],\n",
       " [4.444444444444444e-05],\n",
       " [3.333333333333333e-05],\n",
       " [3.333333333333333e-05],\n",
       " [3.333333333333333e-05],\n",
       " [3.333333333333333e-05],\n",
       " [3.333333333333333e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [2.222222222222222e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [1.111111111111111e-05],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf_cov.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7V1X30S7kkqE",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1637180681601,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "7V1X30S7kkqE"
   },
   "outputs": [],
   "source": [
    "# tA=tA.cpu()\n",
    "# tCov=tCov.cpu()\n",
    "# tsupp=tsupp.cpu()\n",
    "# tprob=tprob.cpu()\n",
    "# SAM=1280\n",
    "# num=0\n",
    "# samp = torch.zeros([TSIZE,N,SAM])\n",
    "# for sam in range(SAM):\n",
    "#     samp[:,:,sam] = tprob.bernoulli()\n",
    "# R=torch.zeros(TSIZE,SAM)\n",
    "# sigma2W = (10**((noisePowerN)/10))*torch.eye(L)\n",
    "# for idx in range(TSIZE):\n",
    "#     CA = tA[idx,:,:].T[:L,:]+1j*tA[idx,:,:].T[L:,:]\n",
    "#     CAT = tA[idx,:,:L]-1j*tA[idx,:,L:]\n",
    "#     CCov = (tCov[idx,:L**2]+1j*tCov[idx,L**2:]).reshape(L,L)\n",
    "#     for sam in range(SAM):\n",
    "#         DD = torch.diag(samp[idx,:,sam])\n",
    "#         CD = DD+1j*torch.zeros(DD.size())\n",
    "#         SIGMA =torch.mm(torch.mm(CA, CD), CAT)+sigma2W\n",
    "#         R[idx,sam] = torch.det(SIGMA).abs().log()+torch.trace(torch.mm(SIGMA.inverse(), CCov)).real\n",
    "# for SAM in [320,640,960,1280]:\n",
    "#   r = R[:,:SAM]\n",
    "#   s = samp[:,:,:SAM]\n",
    "#   bestsamp = r.min(1)[1]\n",
    "#   choice = s[[i for i in range(TSIZE)],:,bestsamp]\n",
    "#   err = N*TSIZE-(choice.numpy()==tsupp.numpy()).sum().sum().item()\n",
    "#   detect = choice.numpy()*tsupp.numpy()\n",
    "#   pm=1-detect.sum()/K/TSIZE\n",
    "#   falarm = choice.numpy()-detect\n",
    "#   pf=falarm.sum()/(N-K)/TSIZE     \n",
    "#   print('Results: Sampling number: {}\\t, Error rate: {}/{} ({:.2f}%)\\n'.format(SAM, err, N*TSIZE, 100. * err/N/TSIZE))  \n",
    "#   print('Probability of missed detection: {:.4f}, Probability of false alarm: {:.4f}\\n'.format(pm,pf))  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "VHVgS7FyqTRK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8151,
     "status": "ok",
     "timestamp": 1637180689751,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "VHVgS7FyqTRK",
    "outputId": "1c5cc015-85fd-40b9-efea-4fe8e05244ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time= 0.01679706573486328\n"
     ]
    }
   ],
   "source": [
    "N=120\n",
    "K=int(N/10)\n",
    "M=64\n",
    "sigma2s = np.ones([N,1])  \n",
    "Pmax=23\n",
    "noisePowerN = -14.188607425695352+(23-Pmax) \n",
    "tA, tCov, tsupp = datasetGeneration(TSIZE,N,J,L,matrx_Type,M,K,txPowerN,noisePowerN,location,channel,use_cov)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    tlogit = model(tA,tCov,mask)\n",
    "    tprob = torch.sigmoid(tlogit)\n",
    "end = time.time()\n",
    "print('time=', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "qU42mEsZqdyF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1795,
     "status": "ok",
     "timestamp": 1637180691539,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "qU42mEsZqdyF",
    "outputId": "f63641ec-379d-487c-da72-ae06d6ac4a67"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM = 200\n",
    "min_g = tprob[tprob>0].min().item()\n",
    "max_g = tprob.max().item()\n",
    "set_1 = np.exp(np.linspace(np.log(min_g*0.95),np.log(max_g*1.05),int(NUM/2)))\n",
    "set_2 = np.linspace(min_g*0.95,max_g*1.05,int(NUM/2))\n",
    "TH = np.sort(np.concatenate((set_1,set_2)))\n",
    "pm_cov = np.zeros([NUM,1])\n",
    "pf_cov = np.zeros([NUM,1])\n",
    "\n",
    "for idx in range(NUM):\n",
    "    th = TH[idx]\n",
    "    th_supp = np.zeros(tsupp.size())\n",
    "    th_supp[(tprob>=th).cpu()]=1\n",
    "    detect = th_supp*(tsupp.cpu().numpy())\n",
    "    pm_cov[idx] = 1-detect.sum()/K/TSIZE\n",
    "    falarm = th_supp-detect\n",
    "    pf_cov[idx] = falarm.sum()/(N-K)/TSIZE \n",
    "\n",
    "plt.plot(pm_cov, pf_cov)  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ADsu6YJkqelb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1637180691539,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "ADsu6YJkqelb",
    "outputId": "c6bb58c7-41c4-4b6d-b749-7884945a9cc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0],\n",
       " [0.0],\n",
       " [0.6829833333333333],\n",
       " [0.7051000000000001],\n",
       " [0.7154],\n",
       " [0.7215333333333334],\n",
       " [0.7271333333333334],\n",
       " [0.7313833333333333],\n",
       " [0.7349666666666667],\n",
       " [0.7379166666666667],\n",
       " [0.7409833333333333],\n",
       " [0.7433833333333333],\n",
       " [0.7454833333333333],\n",
       " [0.7474333333333334],\n",
       " [0.7491666666666666],\n",
       " [0.7506333333333334],\n",
       " [0.7521166666666667],\n",
       " [0.7533333333333334],\n",
       " [0.7545999999999999],\n",
       " [0.7558],\n",
       " [0.7567833333333334],\n",
       " [0.7581333333333333],\n",
       " [0.7589666666666667],\n",
       " [0.7601833333333333],\n",
       " [0.7612333333333333],\n",
       " [0.7621333333333333],\n",
       " [0.76295],\n",
       " [0.7640833333333333],\n",
       " [0.7651],\n",
       " [0.7658],\n",
       " [0.76635],\n",
       " [0.7670333333333333],\n",
       " [0.7679333333333334],\n",
       " [0.7686999999999999],\n",
       " [0.7695333333333334],\n",
       " [0.7703166666666666],\n",
       " [0.7709333333333334],\n",
       " [0.7716333333333334],\n",
       " [0.7721833333333333],\n",
       " [0.7727166666666667],\n",
       " [0.7732],\n",
       " [0.7737666666666667],\n",
       " [0.7744666666666666],\n",
       " [0.7750666666666667],\n",
       " [0.7756000000000001],\n",
       " [0.7762166666666667],\n",
       " [0.77675],\n",
       " [0.7773166666666667],\n",
       " [0.7778166666666666],\n",
       " [0.7784666666666666],\n",
       " [0.7789],\n",
       " [0.7794833333333333],\n",
       " [0.7799],\n",
       " [0.7803166666666667],\n",
       " [0.7809333333333334],\n",
       " [0.7815166666666666],\n",
       " [0.7815166666666666],\n",
       " [0.7820833333333334],\n",
       " [0.7823833333333333],\n",
       " [0.7827500000000001],\n",
       " [0.7832],\n",
       " [0.7838666666666667],\n",
       " [0.7843166666666667],\n",
       " [0.7847166666666666],\n",
       " [0.7848666666666666],\n",
       " [0.7853],\n",
       " [0.7856666666666666],\n",
       " [0.7861333333333334],\n",
       " [0.78645],\n",
       " [0.7866166666666666],\n",
       " [0.7870833333333334],\n",
       " [0.7874666666666666],\n",
       " [0.7876833333333333],\n",
       " [0.7878499999999999],\n",
       " [0.7883166666666667],\n",
       " [0.7887],\n",
       " [0.7888666666666666],\n",
       " [0.7893166666666667],\n",
       " [0.78945],\n",
       " [0.7896833333333333],\n",
       " [0.7901666666666667],\n",
       " [0.7902166666666667],\n",
       " [0.7908333333333334],\n",
       " [0.791],\n",
       " [0.7912333333333333],\n",
       " [0.7915166666666666],\n",
       " [0.7917],\n",
       " [0.7919833333333334],\n",
       " [0.7922],\n",
       " [0.7923833333333333],\n",
       " [0.7925666666666666],\n",
       " [0.7927166666666666],\n",
       " [0.7930833333333334],\n",
       " [0.7931],\n",
       " [0.79345],\n",
       " [0.7935166666666666],\n",
       " [0.7937833333333333],\n",
       " [0.7940666666666667],\n",
       " [0.7940833333333334],\n",
       " [0.7944166666666667],\n",
       " [0.79455],\n",
       " [0.7946333333333333],\n",
       " [0.7948666666666666],\n",
       " [0.795],\n",
       " [0.7952166666666667],\n",
       " [0.7955166666666666],\n",
       " [0.7956166666666666],\n",
       " [0.79575],\n",
       " [0.7959166666666666],\n",
       " [0.7960166666666667],\n",
       " [0.7960833333333334],\n",
       " [0.7962166666666667],\n",
       " [0.7964166666666667],\n",
       " [0.7965166666666667],\n",
       " [0.7966],\n",
       " [0.7968166666666667],\n",
       " [0.7970333333333333],\n",
       " [0.79705],\n",
       " [0.7972333333333333],\n",
       " [0.7973833333333333],\n",
       " [0.7975],\n",
       " [0.79755],\n",
       " [0.7978000000000001],\n",
       " [0.7980666666666667],\n",
       " [0.79825],\n",
       " [0.7984166666666667],\n",
       " [0.7984666666666667],\n",
       " [0.7986],\n",
       " [0.7988666666666666],\n",
       " [0.7990666666666667],\n",
       " [0.7991666666666667],\n",
       " [0.7992666666666667],\n",
       " [0.7994333333333333],\n",
       " [0.7996333333333333],\n",
       " [0.79985],\n",
       " [0.7998833333333333],\n",
       " [0.7999499999999999],\n",
       " [0.8000833333333333],\n",
       " [0.8002333333333334],\n",
       " [0.8004666666666667],\n",
       " [0.8006333333333333],\n",
       " [0.80075],\n",
       " [0.8008166666666667],\n",
       " [0.8010333333333333],\n",
       " [0.8011833333333334],\n",
       " [0.8015],\n",
       " [0.8016666666666666],\n",
       " [0.8017833333333333],\n",
       " [0.8018333333333333],\n",
       " [0.8019166666666666],\n",
       " [0.8020666666666667],\n",
       " [0.8022166666666667],\n",
       " [0.8023833333333333],\n",
       " [0.8025666666666667],\n",
       " [0.8026166666666666],\n",
       " [0.8027166666666666],\n",
       " [0.8029166666666667],\n",
       " [0.8030666666666667],\n",
       " [0.8031833333333334],\n",
       " [0.8033166666666667],\n",
       " [0.8035166666666667],\n",
       " [0.8036],\n",
       " [0.80365],\n",
       " [0.80385],\n",
       " [0.8039833333333333],\n",
       " [0.8041333333333334],\n",
       " [0.8043833333333333],\n",
       " [0.8046333333333333],\n",
       " [0.8048666666666666],\n",
       " [0.8050666666666667],\n",
       " [0.8051],\n",
       " [0.8053833333333333],\n",
       " [0.80565],\n",
       " [0.8059333333333334],\n",
       " [0.8062333333333334],\n",
       " [0.8065333333333333],\n",
       " [0.8067],\n",
       " [0.8069500000000001],\n",
       " [0.8071166666666667],\n",
       " [0.8072833333333334],\n",
       " [0.80755],\n",
       " [0.8080499999999999],\n",
       " [0.8083166666666667],\n",
       " [0.80875],\n",
       " [0.80925],\n",
       " [0.8098166666666666],\n",
       " [0.8103666666666667],\n",
       " [0.81125],\n",
       " [0.81155],\n",
       " [0.8119833333333333],\n",
       " [0.813],\n",
       " [0.8144666666666667],\n",
       " [0.8173666666666667],\n",
       " [0.8242],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm_cov.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "LRgU0NGBqe2A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1637180691540,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "LRgU0NGBqe2A",
    "outputId": "148f5715-f745-4d77-8ed8-6c73ca66176b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0],\n",
       " [1.0],\n",
       " [0.12435185185185185],\n",
       " [0.10840740740740741],\n",
       " [0.10147222222222221],\n",
       " [0.09710925925925926],\n",
       " [0.09393888888888889],\n",
       " [0.0914611111111111],\n",
       " [0.08936481481481481],\n",
       " [0.0875574074074074],\n",
       " [0.08604814814814815],\n",
       " [0.0846611111111111],\n",
       " [0.0834037037037037],\n",
       " [0.08232407407407408],\n",
       " [0.08131111111111111],\n",
       " [0.08045],\n",
       " [0.07956666666666666],\n",
       " [0.07875925925925926],\n",
       " [0.07797777777777778],\n",
       " [0.0772962962962963],\n",
       " [0.07658888888888889],\n",
       " [0.07592592592592592],\n",
       " [0.0753074074074074],\n",
       " [0.07473518518518518],\n",
       " [0.07417777777777779],\n",
       " [0.07367962962962964],\n",
       " [0.07320925925925927],\n",
       " [0.07276851851851852],\n",
       " [0.07232592592592592],\n",
       " [0.07188703703703703],\n",
       " [0.0714925925925926],\n",
       " [0.07109074074074073],\n",
       " [0.07067592592592592],\n",
       " [0.07027962962962964],\n",
       " [0.0699074074074074],\n",
       " [0.06956851851851852],\n",
       " [0.06919074074074073],\n",
       " [0.06885555555555556],\n",
       " [0.06851851851851852],\n",
       " [0.0681962962962963],\n",
       " [0.06785740740740741],\n",
       " [0.06754444444444445],\n",
       " [0.0672537037037037],\n",
       " [0.06696481481481481],\n",
       " [0.06664629629629629],\n",
       " [0.06632222222222221],\n",
       " [0.0660425925925926],\n",
       " [0.06575555555555555],\n",
       " [0.06548518518518519],\n",
       " [0.0651888888888889],\n",
       " [0.06491111111111111],\n",
       " [0.06466296296296296],\n",
       " [0.06440370370370371],\n",
       " [0.06417037037037036],\n",
       " [0.06393333333333334],\n",
       " [0.06370555555555556],\n",
       " [0.0637037037037037],\n",
       " [0.06343518518518519],\n",
       " [0.06320925925925926],\n",
       " [0.06295],\n",
       " [0.06273148148148147],\n",
       " [0.06251481481481481],\n",
       " [0.062277777777777786],\n",
       " [0.062094444444444445],\n",
       " [0.06202962962962963],\n",
       " [0.06182037037037037],\n",
       " [0.06162962962962963],\n",
       " [0.06142777777777778],\n",
       " [0.061255555555555556],\n",
       " [0.06121481481481481],\n",
       " [0.06096666666666666],\n",
       " [0.06073333333333334],\n",
       " [0.060612962962962966],\n",
       " [0.06054074074074074],\n",
       " [0.060261111111111106],\n",
       " [0.06011851851851852],\n",
       " [0.06007037037037037],\n",
       " [0.05984444444444444],\n",
       " [0.059724074074074075],\n",
       " [0.0596074074074074],\n",
       " [0.05939074074074074],\n",
       " [0.05938148148148148],\n",
       " [0.059201851851851846],\n",
       " [0.059138888888888894],\n",
       " [0.05898888888888889],\n",
       " [0.05888148148148148],\n",
       " [0.05876296296296297],\n",
       " [0.058640740740740736],\n",
       " [0.0585425925925926],\n",
       " [0.05845],\n",
       " [0.05834629629629629],\n",
       " [0.058268518518518525],\n",
       " [0.058122222222222214],\n",
       " [0.0581],\n",
       " [0.05793333333333334],\n",
       " [0.05789629629629629],\n",
       " [0.05778518518518518],\n",
       " [0.057696296296296294],\n",
       " [0.057664814814814815],\n",
       " [0.05753333333333334],\n",
       " [0.05747962962962963],\n",
       " [0.05740185185185185],\n",
       " [0.05726481481481482],\n",
       " [0.0572074074074074],\n",
       " [0.05714814814814815],\n",
       " [0.05702777777777778],\n",
       " [0.056988888888888894],\n",
       " [0.05693888888888889],\n",
       " [0.05683703703703703],\n",
       " [0.056774074074074074],\n",
       " [0.05674814814814815],\n",
       " [0.05665925925925926],\n",
       " [0.05656296296296297],\n",
       " [0.05653703703703703],\n",
       " [0.05647962962962963],\n",
       " [0.056385185185185184],\n",
       " [0.056294444444444446],\n",
       " [0.05628518518518519],\n",
       " [0.05619074074074074],\n",
       " [0.05610925925925926],\n",
       " [0.056016666666666666],\n",
       " [0.056],\n",
       " [0.055935185185185185],\n",
       " [0.055855555555555554],\n",
       " [0.05578148148148148],\n",
       " [0.05572592592592592],\n",
       " [0.05569814814814815],\n",
       " [0.05561851851851852],\n",
       " [0.05555],\n",
       " [0.05545555555555556],\n",
       " [0.055427777777777784],\n",
       " [0.055398148148148155],\n",
       " [0.05532222222222222],\n",
       " [0.05525185185185185],\n",
       " [0.05517592592592593],\n",
       " [0.05512222222222222],\n",
       " [0.05510925925925926],\n",
       " [0.05502962962962963],\n",
       " [0.05495925925925926],\n",
       " [0.05489629629629629],\n",
       " [0.05481111111111111],\n",
       " [0.05477592592592592],\n",
       " [0.05474444444444444],\n",
       " [0.054677777777777783],\n",
       " [0.05458518518518519],\n",
       " [0.0545],\n",
       " [0.05442037037037037],\n",
       " [0.05437777777777778],\n",
       " [0.05435370370370371],\n",
       " [0.05429814814814815],\n",
       " [0.05420925925925926],\n",
       " [0.05413333333333334],\n",
       " [0.054064814814814816],\n",
       " [0.054009259259259264],\n",
       " [0.053987037037037035],\n",
       " [0.05393333333333334],\n",
       " [0.0538574074074074],\n",
       " [0.05377962962962963],\n",
       " [0.053698148148148155],\n",
       " [0.05362037037037037],\n",
       " [0.053564814814814815],\n",
       " [0.053503703703703706],\n",
       " [0.0534925925925926],\n",
       " [0.0534],\n",
       " [0.05331851851851852],\n",
       " [0.05325],\n",
       " [0.05316666666666666],\n",
       " [0.0530925925925926],\n",
       " [0.053003703703703706],\n",
       " [0.05293333333333334],\n",
       " [0.05292777777777778],\n",
       " [0.05282407407407408],\n",
       " [0.052725925925925926],\n",
       " [0.052612962962962966],\n",
       " [0.0525074074074074],\n",
       " [0.05238703703703703],\n",
       " [0.05226851851851852],\n",
       " [0.052144444444444445],\n",
       " [0.05202962962962963],\n",
       " [0.05198888888888889],\n",
       " [0.051837037037037036],\n",
       " [0.051666666666666666],\n",
       " [0.05147962962962963],\n",
       " [0.05131666666666666],\n",
       " [0.05112407407407408],\n",
       " [0.05093333333333333],\n",
       " [0.0506462962962963],\n",
       " [0.050381481481481485],\n",
       " [0.05025740740740741],\n",
       " [0.05001111111111111],\n",
       " [0.04955],\n",
       " [0.04887407407407408],\n",
       " [0.04783703703703704],\n",
       " [0.045],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf_cov.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "JWeODktyXxqa",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1637180691540,
     "user": {
      "displayName": "Yang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15800938627415374412"
     },
     "user_tz": -480
    },
    "id": "JWeODktyXxqa"
   },
   "outputs": [],
   "source": [
    "        "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
